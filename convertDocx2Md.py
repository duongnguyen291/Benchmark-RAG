#!/usr/bin/env python
# -*- coding: utf-8 -*-

import argparse
import subprocess
from pathlib import Path
import sys
import shutil
import re
from bs4 import BeautifulSoup

def check_pandoc():
    try:
        subprocess.run(["pandoc", "-v"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("‚ùå Pandoc ch∆∞a c√†i ho·∫∑c kh√¥ng c√≥ trong PATH. H√£y c√†i Pandoc r·ªìi th·ª≠ l·∫°i.")
        sys.exit(1)

def html_table_to_pipe(html_content):
    """Convert HTML tables to pipe markdown tables"""
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        tables = soup.find_all('table')
        
        for table in tables:
            # Extract table data
            rows = []
            for tr in table.find_all('tr'):
                row = []
                for td in tr.find_all(['td', 'th']):
                    # Get text content and clean it
                    cell_text = td.get_text(strip=True).replace('\n', ' ').replace('|', '\\|')
                    row.append(cell_text if cell_text else ' ')
                if row:  # Only add non-empty rows
                    rows.append(row)
            
            if not rows:
                continue
                
            # Create pipe table
            pipe_table = []
            
            # Add header row
            if rows:
                header = '| ' + ' | '.join(rows[0]) + ' |'
                pipe_table.append(header)
                
                # Add separator row
                separator = '|' + '|'.join(['---' for _ in rows[0]]) + '|'
                pipe_table.append(separator)
                
                # Add data rows
                for row in rows[1:]:
                    # Pad row to match header length
                    while len(row) < len(rows[0]):
                        row.append(' ')
                    data_row = '| ' + ' | '.join(row[:len(rows[0])]) + ' |'
                    pipe_table.append(data_row)
            
            # Replace HTML table with pipe table
            pipe_table_str = '\n' + '\n'.join(pipe_table) + '\n'
            table.replace_with(pipe_table_str)
        
        return str(soup)
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi convert HTML table: {e}")
        return html_content

def convert_docx_to_md(src_path: Path, out_dir: Path, overwrite: bool = False, wrap_none: bool = True, use_html_tables: bool = False):
    """Convert m·ªôt file .docx sang .md (GFM) v·ªõi media tr√≠ch xu·∫•t ri√™ng theo t√™n file."""
    stem = src_path.stem
    out_md = out_dir / f"{stem}.md"
    media_dir = out_dir / f"{stem}_media"

    if out_md.exists() and not overwrite:
        print(f"‚Ü∑ B·ªè qua (ƒë√£ t·ªìn t·∫°i): {out_md}")
        return True

    # X√≥a th∆∞ m·ª•c media c≈© n·∫øu overwrite
    if overwrite and media_dir.exists():
        shutil.rmtree(media_dir)

    # Lu√¥n cho ph√©p HTML tables trong qu√° tr√¨nh convert, sau ƒë√≥ post-process
    target = "gfm+footnotes+pipe_tables+tex_math_dollars+raw_html"

    # T√πy ch·ªçn cho Pandoc
    cmd = [
        "pandoc",
        str(src_path),
        "-t", target,
        "--extract-media", str(media_dir),
        "--markdown-headings=atx",
        "-o", str(out_md),
        "--columns=200"
    ]
    
    if wrap_none:
        cmd.extend(["--wrap=none"])

    # Th·ª±c thi Pandoc
    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        
        # Post-process: Convert HTML tables to pipe tables n·∫øu c·∫ßn
        if not use_html_tables:
            try:
                with open(out_md, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Convert HTML tables to pipe tables
                converted_content = html_table_to_pipe(content)
                
                # Clean up BeautifulSoup artifacts
                converted_content = re.sub(r'<html><body>', '', converted_content)
                converted_content = re.sub(r'</body></html>', '', converted_content)
                converted_content = converted_content.strip()
                
                with open(out_md, 'w', encoding='utf-8') as f:
                    f.write(converted_content)
                    
                print(f"‚úÖ Converted: {src_path.name} ‚Üí {out_md.name} (tables: pipe)")
            except Exception as e:
                print(f"‚ö†Ô∏è  Converted v·ªõi HTML tables: {src_path.name} ‚Üí {out_md.name} (l·ªói post-process: {e})")
        else:
            print(f"‚úÖ Converted: {src_path.name} ‚Üí {out_md.name} (tables: HTML)")
            
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"‚ùå L·ªói khi chuy·ªÉn: {src_path} -> {out_md}")
        print(f"   Command: {' '.join(cmd)}")
        print(f"   Error: {e.stderr if e.stderr else str(e)}")
        return False

def main():
    parser = argparse.ArgumentParser(description="Batch convert .docx ‚Üí Markdown (GFM) b·∫±ng Pandoc. M·∫∑c ƒë·ªãnh convert HTML tables th√†nh pipe tables.")
    parser.add_argument("input_dir", type=str, help="Th∆∞ m·ª•c ch·ª©a .docx")
    parser.add_argument("output_dir", type=str, help="Th∆∞ m·ª•c l∆∞u .md v√† media")
    parser.add_argument("--recursive", action="store_true", help="Qu√©t ƒë·ªá quy to√†n b·ªô th∆∞ m·ª•c con")
    parser.add_argument("--overwrite", action="store_true", help="Ghi ƒë√® file .md v√† media n·∫øu ƒë√£ t·ªìn t·∫°i")
    parser.add_argument("--no-wrap-none", action="store_true", help="Kh√¥ng d√πng --wrap=none (m·∫∑c ƒë·ªãnh c√≥)")
    parser.add_argument("--html-tables", action="store_true", help="Gi·ªØ b·∫£ng HTML thay v√¨ convert th√†nh pipe (m·∫∑c ƒë·ªãnh l√† pipe)")
    args = parser.parse_args()

    in_dir = Path(args.input_dir).expanduser().resolve()
    out_dir = Path(args.output_dir).expanduser().resolve()

    if not in_dir.exists() or not in_dir.is_dir():
        print("‚ùå input_dir kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng ph·∫£i th∆∞ m·ª•c.")
        sys.exit(1)

    out_dir.mkdir(parents=True, exist_ok=True)

    check_pandoc()
    
    # Check if BeautifulSoup is available
    if not args.html_tables:
        try:
            import bs4
        except ImportError:
            print("‚ùå C·∫ßn c√†i beautifulsoup4 ƒë·ªÉ convert HTML tables th√†nh pipe:")
            print("   pip install beautifulsoup4")
            sys.exit(1)

    pattern = "**/*.docx" if args.recursive else "*.docx"
    files = sorted(in_dir.glob(pattern))
    if not files:
        print("‚ü° Kh√¥ng t√¨m th·∫•y file .docx n√†o.")
        sys.exit(0)

    print(f"üìù T√¨m th·∫•y {len(files)} file .docx")
    print(f"üìÅ ƒê·∫ßu ra: {out_dir}")
    print(f"üìã ƒê·ªãnh d·∫°ng b·∫£ng: {'HTML' if args.html_tables else 'Pipe markdown (post-processed)'}")
    print()

    ok = fail = 0
    for f in files:
        if convert_docx_to_md(
            src_path=f,
            out_dir=out_dir,
            overwrite=args.overwrite,
            wrap_none=not args.no_wrap_none,
            use_html_tables=args.html_tables
        ):
            ok += 1
        else:
            fail += 1

    print(f"\n‚Äî T·ªîNG K·∫æT ‚Äî")
    print(f"  Th√†nh c√¥ng: {ok}")
    print(f"  Th·∫•t b·∫°i : {fail}")
    print(f"  ƒê·∫ßu ra   : {out_dir}")

if __name__ == "__main__":
    main()